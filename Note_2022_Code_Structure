Module used and role：
  time.time(): 统计的wall time(即墙上时钟)，也就是系统时钟的时间戳
  argparse: python自带的命令行参数解析包，可以用来方便地读取命令行参数
  numpy
  torch
    torch.nn.functional：F.nll_loss损失函数,多分类任务
    torch.optim：优化器
 
FILE Flow:
  train.py 
    utils.py  load_data
    models.py  GCN
      layers.py GraphConvolution
    utils.py  accuracy

CODE FLOW
 train.py:
 1 参数设置：epochs, lr, weight_decay, hidden, dropout
 2 读取数据: adj, features, labels, idx_train, idx_val, idx_test 
      utils.py   utils.load_data      
        np.genfromtxt读取数据为nparray格式，提取属性矩阵，标签one_hot化
        sp.csr_matrix: 行列序号和对应的值来表示矩阵 
        idx_features_labels[:,1:-1] : 每一行的去头去尾，得到属性的one-hot矩阵
        enumerate：返回列表的索引，值
        sp.coo_matrix: 构造邻接矩阵，表示类型同sp.csr_matrix
        sp.diags：数列构成对角化矩阵（节点one-hot属性向量处理后的结果）
        matrix1.dot(matrix2): 矩阵点乘
        torch.sparse.FloatTensor：由边和边上的值 构建稀疏矩阵
       返回
       adj：tensor稀疏矩阵（row-normalize后的邻接矩阵）
       features：tensor矩阵 2708*1433（节点数*one-hot属性向量长度  row-normalize后）
       labels：tensor1维向量，每个节点的标签
       idx_train, idx_val, idx_test：1维tensor数据
  3 建立模型: 特征维度，隐藏层大小，类别数(输出维度)，超参数
    models.py 
    建立gcn隐藏层  layers.py
  4 设置优化器
  5 训练 
    6 model.forward(features，adj)  ####卷积过程
        gcn1.forward(features，adj) —— relu{adj(2708,2708)*[features(2708,1433)*weight(1433,nhid)]} → x(2708,nhid)
          support = torch.mm(features, weight) 矩阵乘法
          torch.spmm(adi,support) 矩阵乘法（稀疏矩阵乘dense矩阵）
        gcn2.forward(x1,adj) —— adj(2708,2708)*(x(2708,nhid)*weight2(nhid,nclass)) → x(2708,nclass)
        输出log_softmax(x)
     7 计算loss
     8 计算训练集accuracy
     9 反向传播
     10 计算验证集数据accuracy（不进行反向传播）
     
      
     
